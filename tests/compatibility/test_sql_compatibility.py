#!/usr/bin/env python3
"""
æµ‹è¯•SQLå…¼å®¹æ€§

éªŒè¯ä¿®æ”¹åçš„SQLè¯­å¥æ˜¯å¦ä¸difyä¸»é¡¹ç›®å…¼å®¹
"""

import os
import sys
import json
import time
import uuid
import numpy as np

# æ·»åŠ å·¥å…·è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'tools'))

try:
    from lakehouse_connection import LakehouseConnection
except ImportError as e:
    print(f"âŒ æ— æ³•å¯¼å…¥lakehouse_connection: {e}")
    sys.exit(1)

class SQLCompatibilityTest:
    """SQLå…¼å®¹æ€§æµ‹è¯•"""
    
    def __init__(self):
        self.test_collection = f"test_sql_{int(time.time())}"
        self.test_schema = "dify"
        self.test_dimension = 1536
        
        self.config = {
            "username": os.getenv("CLICKZETTA_USERNAME"),
            "password": os.getenv("CLICKZETTA_PASSWORD"),
            "instance": os.getenv("CLICKZETTA_INSTANCE"),
            "service": os.getenv("CLICKZETTA_SERVICE", "uat-api.clickzetta.com"),
            "workspace": os.getenv("CLICKZETTA_WORKSPACE", "quick_start"),
            "vcluster": os.getenv("CLICKZETTA_VCLUSTER", "default_ap"),
            "schema": self.test_schema
        }
        
        self.connection = None
        self.test_results = {}
    
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        try:
            conn_manager = LakehouseConnection()
            self.connection = conn_manager.get_connection(self.config)
            print("âœ… è¿æ¥å»ºç«‹æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    def test_table_creation_sql(self) -> bool:
        """æµ‹è¯•è¡¨åˆ›å»ºSQL (ä¿®æ”¹åçš„å·¥å…·æ ¼å¼)"""
        print("\nğŸ§ª æµ‹è¯•è¡¨åˆ›å»ºSQL...")
        
        try:
            with self.connection.cursor() as cursor:
                # ä½¿ç”¨ä¿®æ”¹åçš„è¡¨åˆ›å»ºSQL
                create_table_sql = f"""
                CREATE TABLE IF NOT EXISTS {self.test_schema}.{self.test_collection} (
                    id STRING NOT NULL,
                    page_content STRING NOT NULL,
                    metadata JSON,
                    vector VECTOR(FLOAT, {self.test_dimension}) NOT NULL,
                    PRIMARY KEY (id)
                )
                """
                
                cursor.execute(create_table_sql)
                print("âœ… è¡¨åˆ›å»ºSQLæ‰§è¡ŒæˆåŠŸ")
                
                # éªŒè¯è¡¨ç»“æ„
                cursor.execute(f"DESC {self.test_schema}.{self.test_collection}")
                columns = cursor.fetchall()
                
                field_names = [col[0] for col in columns]
                expected_fields = ["id", "page_content", "metadata", "vector"]
                
                missing_fields = [field for field in expected_fields if field not in field_names]
                if missing_fields:
                    print(f"âŒ ç¼ºå°‘å­—æ®µ: {missing_fields}")
                    return False
                
                print("âœ… è¡¨ç»“æ„éªŒè¯é€šè¿‡")
                self.test_results['table_creation'] = True
                return True
                
        except Exception as e:
            print(f"âŒ è¡¨åˆ›å»ºSQLæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['table_creation'] = False
            return False
    
    def test_index_creation_sql(self) -> bool:
        """æµ‹è¯•ç´¢å¼•åˆ›å»ºSQL (ä¿®æ”¹åçš„å·¥å…·æ ¼å¼)"""
        print("\nğŸ§ª æµ‹è¯•ç´¢å¼•åˆ›å»ºSQL...")
        
        try:
            with self.connection.cursor() as cursor:
                # åˆ›å»ºHNSWå‘é‡ç´¢å¼•
                vector_index_name = f"idx_{self.test_collection}_vector"
                
                vector_index_sql = f"""
                CREATE VECTOR INDEX IF NOT EXISTS {vector_index_name}
                ON TABLE {self.test_schema}.{self.test_collection}(vector)
                PROPERTIES (
                    "distance.function" = "cosine_distance",
                    "scalar.type" = "f32",
                    "m" = "16",
                    "ef.construction" = "128"
                )
                """
                
                cursor.execute(vector_index_sql)
                print("âœ… HNSWå‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
                
                # åˆ›å»ºå€’æ’ç´¢å¼•
                text_index_name = f"idx_{self.test_collection}_text"
                
                text_index_sql = f"""
                CREATE INVERTED INDEX IF NOT EXISTS {text_index_name}
                ON TABLE {self.test_schema}.{self.test_collection} (page_content)
                PROPERTIES (
                    "analyzer" = "chinese",
                    "mode" = "smart"
                )
                """
                
                try:
                    cursor.execute(text_index_sql)
                    print("âœ… å€’æ’ç´¢å¼•åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ å€’æ’ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼ˆä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ï¼‰: {e}")
                
                self.test_results['index_creation'] = True
                return True
                
        except Exception as e:
            print(f"âŒ ç´¢å¼•åˆ›å»ºSQLæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['index_creation'] = False
            return False
    
    def test_data_insertion_sql(self) -> bool:
        """æµ‹è¯•æ•°æ®æ’å…¥SQL (ä¿®æ”¹åçš„å·¥å…·æ ¼å¼)"""
        print("\nğŸ§ª æµ‹è¯•æ•°æ®æ’å…¥SQL...")
        
        try:
            with self.connection.cursor() as cursor:
                # å‡†å¤‡æµ‹è¯•æ•°æ®
                test_data = []
                for i in range(3):
                    doc_id = f"test_doc_{i+1}_{uuid.uuid4()}"
                    content = f"æµ‹è¯•æ–‡æ¡£ {i+1}: è¿™æ˜¯ä¿®æ”¹åçš„å·¥å…·æ ¼å¼æµ‹è¯•å†…å®¹ã€‚"
                    metadata = {
                        "doc_id": doc_id,
                        "document_id": f"doc_{i+1}",
                        "source": "sql_test",
                        "index": i
                    }
                    vector = np.random.random(self.test_dimension).tolist()
                    test_data.append((doc_id, content, metadata, vector))
                
                # ä½¿ç”¨ä¿®æ”¹åçš„æ’å…¥SQLæ ¼å¼
                values = []
                for doc_id, content, metadata, vector in test_data:
                    vector_str = f"VECTOR({','.join(map(str, vector))})"
                    metadata_str = json.dumps(metadata, ensure_ascii=False).replace("'", "''")
                    content_str = content.replace("'", "''")
                    
                    values.append(f"('{doc_id}', '{content_str}', JSON '{metadata_str}', {vector_str})")
                
                insert_sql = f"""
                INSERT INTO {self.test_schema}.{self.test_collection} (id, page_content, metadata, vector)
                VALUES {','.join(values)}
                """
                
                cursor.execute(insert_sql)
                print("âœ… æ•°æ®æ’å…¥SQLæ‰§è¡ŒæˆåŠŸ")
                
                # éªŒè¯æ•°æ®
                cursor.execute(f"SELECT COUNT(*) FROM {self.test_schema}.{self.test_collection}")
                count = cursor.fetchone()[0]
                
                if count != len(test_data):
                    print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: æœŸæœ›{len(test_data)}, å®é™…{count}")
                    return False
                
                print("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                self.test_results['data_insertion'] = True
                return True
                
        except Exception as e:
            print(f"âŒ æ•°æ®æ’å…¥SQLæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['data_insertion'] = False
            return False
    
    def test_search_sql(self) -> bool:
        """æµ‹è¯•æœç´¢SQL (ä¿®æ”¹åçš„å·¥å…·æ ¼å¼)"""
        print("\nğŸ§ª æµ‹è¯•æœç´¢SQL...")
        
        try:
            with self.connection.cursor() as cursor:
                # å‘é‡æœç´¢SQL
                query_vector = np.random.random(self.test_dimension).tolist()
                vector_str = f"VECTOR({','.join(map(str, query_vector))})"
                
                search_sql = f"""
                SELECT id, page_content, metadata,
                       COSINE_DISTANCE(vector, {vector_str}) AS distance
                FROM {self.test_schema}.{self.test_collection}
                ORDER BY distance
                LIMIT 3
                """
                
                cursor.execute(search_sql)
                results = cursor.fetchall()
                
                print(f"âœ… å‘é‡æœç´¢SQLæ‰§è¡ŒæˆåŠŸï¼Œè¿”å›{len(results)}ä¸ªç»“æœ")
                
                # å…¨æ–‡æœç´¢SQL
                search_query = "æµ‹è¯•æ–‡æ¡£"
                
                text_search_sql = f"""
                SELECT id, page_content, metadata
                FROM {self.test_schema}.{self.test_collection}
                WHERE page_content LIKE '%{search_query}%'
                LIMIT 3
                """
                
                cursor.execute(text_search_sql)
                text_results = cursor.fetchall()
                
                print(f"âœ… å…¨æ–‡æœç´¢SQLæ‰§è¡ŒæˆåŠŸï¼Œè¿”å›{len(text_results)}ä¸ªç»“æœ")
                
                self.test_results['search_sql'] = True
                return True
                
        except Exception as e:
            print(f"âŒ æœç´¢SQLæµ‹è¯•å¤±è´¥: {e}")
            self.test_results['search_sql'] = False
            return False
    
    def test_compatibility_with_dify(self) -> bool:
        """æµ‹è¯•ä¸difyä¸»é¡¹ç›®çš„å…¼å®¹æ€§"""
        print("\nğŸ§ª æµ‹è¯•ä¸difyä¸»é¡¹ç›®çš„å…¼å®¹æ€§...")
        
        try:
            with self.connection.cursor() as cursor:
                # æ¨¡æ‹Ÿdifyä¸»é¡¹ç›®çš„æŸ¥è¯¢æ–¹å¼
                cursor.execute(f"SELECT id, page_content, metadata FROM {self.test_schema}.{self.test_collection} LIMIT 1")
                result = cursor.fetchone()
                
                if not result:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®")
                    return False
                
                doc_id, content, metadata_json = result
                
                # éªŒè¯æ•°æ®æ ¼å¼
                if not isinstance(doc_id, str):
                    print(f"âŒ IDç±»å‹é”™è¯¯: {type(doc_id)}")
                    return False
                
                if not isinstance(content, str):
                    print(f"âŒ å†…å®¹ç±»å‹é”™è¯¯: {type(content)}")
                    return False
                
                try:
                    metadata = json.loads(metadata_json) if metadata_json else {}
                    if not isinstance(metadata, dict):
                        print(f"âŒ å…ƒæ•°æ®ç±»å‹é”™è¯¯: {type(metadata)}")
                        return False
                except:
                    print(f"âŒ å…ƒæ•°æ®JSONè§£æå¤±è´¥")
                    return False
                
                print("âœ… æ•°æ®æ ¼å¼ä¸difyä¸»é¡¹ç›®å…¼å®¹")
                
                # éªŒè¯å­—æ®µé¡ºåºå’Œå‘½å
                cursor.execute(f"DESC {self.test_schema}.{self.test_collection}")
                columns = cursor.fetchall()
                
                field_names = [col[0] for col in columns]
                expected_order = ["id", "page_content", "metadata", "vector"]
                
                # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨
                for field in expected_order:
                    if field not in field_names:
                        print(f"âŒ ç¼ºå°‘å…³é”®å­—æ®µ: {field}")
                        return False
                
                print("âœ… å­—æ®µç»“æ„ä¸difyä¸»é¡¹ç›®å…¼å®¹")
                
                self.test_results['dify_compatibility'] = True
                return True
                
        except Exception as e:
            print(f"âŒ difyå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
            self.test_results['dify_compatibility'] = False
            return False
    
    def cleanup(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        try:
            if self.connection:
                with self.connection.cursor() as cursor:
                    cursor.execute(f"DROP TABLE IF EXISTS {self.test_schema}.{self.test_collection}")
                print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è­¦å‘Š: {e}")
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š SQLå…¼å®¹æ€§æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        passed_tests = sum(1 for result in self.test_results.values() if result)
        total_tests = len(self.test_results)
        
        print(f"æµ‹è¯•é›†åˆ: {self.test_collection}")
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•: {total_tests - passed_tests}")
        print(f"é€šè¿‡ç‡: {(passed_tests/total_tests)*100:.1f}%")
        
        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for test_name, result in self.test_results.items():
            status_icon = "âœ…" if result else "âŒ"
            print(f"  {status_icon} {test_name}: {'é€šè¿‡' if result else 'å¤±è´¥'}")
        
        if passed_tests == total_tests:
            print("\nğŸ‰ æ‰€æœ‰SQLå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")
            print("âœ… ä¿®æ”¹åçš„clickzetta_difyå·¥å…·ä¸difyä¸»é¡¹ç›®å®Œå…¨å…¼å®¹")
        else:
            print(f"\nâš ï¸ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹SQLå…¼å®¹æ€§æµ‹è¯•")
        print("="*60)
        
        if not self.setup_connection():
            print("âŒ è¿æ¥å¤±è´¥ï¼Œæµ‹è¯•ä¸­æ­¢")
            return
        
        try:
            # è¿è¡Œæµ‹è¯•
            self.test_table_creation_sql()
            self.test_index_creation_sql()
            self.test_data_insertion_sql()
            self.test_search_sql()
            self.test_compatibility_with_dify()
            
            # ç”ŸæˆæŠ¥å‘Š
            self.generate_report()
            
        finally:
            self.cleanup()


def main():
    """ä¸»å‡½æ•°"""
    try:
        test = SQLCompatibilityTest()
        test.run_all_tests()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()